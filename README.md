# ğŸš€ Pipeline E2E Data Engineering Project - AWS

Este repositorio contiene un **proyecto completo de Data Engineering end-to-end**, donde se implementa un pipeline **ETL real en AWS**, integrando servicios clave del ecosistema cloud y siguiendo buenas prÃ¡cticas de arquitectura, seguridad y data wrangling.

El objetivo principal de este proyecto es **demostrar, de forma prÃ¡ctica**, cÃ³mo diseÃ±ar, construir y ejecutar un flujo de datos desde un **Data Lake en S3** hasta un **Data Warehouse en Amazon Redshift**, utilizando **AWS Glue (Visual ETL)** como motor de transformaciÃ³n.

---

## ğŸ§© Arquitectura General

La arquitectura del proyecto estÃ¡ diseÃ±ada para un escenario real de analÃ­tica de datos en la nube:

- **Amazon S3** â†’ Data Lake (datos fuente en formato JSON/CSV)
- **AWS Glue**
  - Crawlers para inferencia de esquemas
  - Data Catalog para gestiÃ³n de metadatos
  - Visual ETL para transformaciones y orquestaciÃ³n
- **Amazon Redshift Serverless** â†’ Data Warehouse
- **IAM** â†’ Roles y permisos bajo el principio de mÃ­nimo privilegio
- **VPC + Endpoint a S3** â†’ Conectividad privada y segura entre servicios

ğŸ“Œ El flujo evita dependencias innecesarias y prioriza servicios **serverless**, reduciendo complejidad operativa.

---

## ğŸ”„ Flujo ETL (Extract, Transform, Load)

1. **Extract**
   - Los datos se almacenan inicialmente en Amazon S3.
   - AWS Glue Crawler infiere el esquema y crea las tablas en el Data Catalog.

2. **Transform**
   - Limpieza de datos:
     - EliminaciÃ³n de filas completamente nulas
     - EliminaciÃ³n de registros duplicados
   - Transformaciones mediante SQL en Glue:
     - Manejo de valores nulos con `COALESCE`
     - CreaciÃ³n de columnas calculadas
   - Ajuste de tipos de datos con `Change Schema` para asegurar compatibilidad con Redshift.

3. **Load**
   - Carga de datos en Amazon Redshift Serverless usando el nodo **Amazon Redshift (Target)**.
   - Estrategia de carga:
     - `MERGE` (UPSERT) para evitar duplicados y mantener consistencia.

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- Amazon S3
- AWS Glue (Crawler, Data Catalog, Visual ETL)
- Amazon Redshift Serverless
- AWS IAM
- Amazon VPC (Endpoint Gateway a S3)
- SQL (para transformaciones y modelado)

---

## ğŸ“‚ Estructura del Repositorio

```text
â”œâ”€â”€ documentation/        # DocumentaciÃ³n detallada del proyecto
â”œâ”€â”€ sql/                  # Queries SQL usadas en Redshift y Glue
â”œâ”€â”€ assets/               # Datos de prueba (JSON)
â”œâ”€â”€ architecture/         # Diagrama de arquitectura
â””â”€â”€ README.md             # DescripciÃ³n general del proyecto
```
---

## ğŸ“º Recursos del Proyecto

* ğŸ¥ YouTube (paso a paso del proyecto):
[Link Playlist](https://www.youtube.com/playlist?list=PLx9ZJhSt41bP1KCzRhpU0gHHe8bUkKKmq)

* ğŸ“„ DocumentaciÃ³n completa del proceso:
Disponible en este repositorio dentro de la carpeta `/documentation`

Este proyecto estÃ¡ pensado como material educativo y de portafolio, enfocado en aprendizaje prÃ¡ctico y resoluciÃ³n de problemas reales en Data Engineering.

---

## ğŸ‘¤ Autor

Brayan Neciosup |
Data & Cloud Engineering Jr. ğŸ“Š

- ğŸŒ [Portafolio Web](https://bryanneciosup626.wixsite.com/brayandataanalitics)
- ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/brayan-rafael-neciosup-bola%C3%B1os-407a59246/)
- ğŸ“¬ Contacto: brayanneciosup626@gmail.com
- ğŸ¦ [Youtube](https://www.youtube.com/@brayanneciosup9873)